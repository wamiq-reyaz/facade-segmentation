{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modify the 12-target classifier for low-rank classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This modifies the 12-target (i12), segnet classifier to use low rank filters. \n",
    "Before using this you should:\n",
    "- Have pycaffe (from https://github.com/alexgkendall/caffe-segnet) setup and on the path\n",
    "- Have a copy of solver.prototxt\n",
    "- Have a copy of the 12-target segnet training classifier (e.g. `../scripts/i12/training.prototxt`)\n",
    "- Have a copy of the 12-target segnet inference classifier (e.g. `../scripts/i12/deploy/deploy.prototxt`)\n",
    "\n",
    "Table of contents:\n",
    "- [Utility Functions](#Utility-Functions)\n",
    "- [Add Low Rank Filter (Function)](#Add-Low-Rank-Filters)\n",
    "- [Generate the Training Net](#Generate-the-net-to-use-for-training)\n",
    "- [Generate the Inference Net](#Generate-the-net-to-use-for-inference-/-testing)\n",
    "- [Test the Net](#Final-Test)\n",
    "- [Modify the Solver Prototxt](#Set-the-solver-parameters-to-use-the-new-net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pylab notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import google.protobuf.text_format\n",
    "import caffe\n",
    "caffe.set_mode_cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For debugging (cell can be removed from final notebook)\n",
    "from IPython.core.debugger import Tracer\n",
    "set_trace = Tracer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_net_proto(path):\n",
    "    \"\"\"Read a net from a prototxt file\n",
    "    \n",
    "    :param path: The path to a caffe network (.prototxt file)\n",
    "    \n",
    "    :return: The prototxt object\n",
    "    :rtype: caffe.proto.caffe_pb2.NetParameter\n",
    "    \"\"\"\n",
    "    net = caffe.proto.caffe_pb2.NetParameter()\n",
    "    with open(path) as f:\n",
    "        proto = f.read()\n",
    "    google.protobuf.text_format.Parse(proto, net)\n",
    "    return net\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summarize_net(train_net):\n",
    "    \"\"\" Print a (not sooo short) summary of the net layers\n",
    "    \n",
    "    :param net: A net \n",
    "    :type net: caffe.proto.caffe_pb2.NetParameter\n",
    "    \"\"\"\n",
    "    layers = list(train_net.layer)\n",
    "    for i, layer in enumerate(layers):\n",
    "        print \"{:04}\".format(i),\n",
    "        print \"\\t{:15}\\t{:15}\".format(layer.name, layer.type),\n",
    "        if layer.type==\"Convolution\":\n",
    "            if layer.convolution_param.kernel_size > 0:\n",
    "                print \"\\t{0:>2}x{0:<2}\".format(layer.convolution_param.kernel_size),\n",
    "            else:\n",
    "                print \"\\t{:>2}x{:<2}\".format(layer.convolution_param.kernel_w, layer.convolution_param.kernel_h),                \n",
    "        else:\n",
    "            print \"\\t{:5}\".format(''),\n",
    "\n",
    "        if \"_D\" in layer.name:\n",
    "            print \"DECODE\"\n",
    "        else:\n",
    "            print \"      \"\n",
    "\n",
    "    print \"Total\", len(layers), \"layers\"   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Low Rank Filters\n",
    "In order to force the net to use low rank filter, we do two different convolutions. First, a 1x9 horzontal convolution, followed by a 1x9 vertical convolution. The result of these two layers is a 9x9 rank 1 convolution. The idea is that we beleive this convolution will favor grid-shaped results. \n",
    "\n",
    "**NOTE:** In order to get the net to behave properly I added a batch normalization layer in between the horizontal and vertical convolutions. The batch normalization does not substantially change the nature of the filters -- they are still rank 1 filters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modify_layers_for_anisotropy(orig_net):\n",
    "    \"\"\"Create a new net that is a copy of `orig_net`, with some layers modified \n",
    "    \n",
    "    This modifies the square '_D' layers of `orig_net` whith two 1D (horizontal and vertical) convolutions. \n",
    "    \n",
    "    :return: A copy of orig_net with additional layers. \n",
    "    \"\"\"\n",
    "    net= caffe.proto.caffe_pb2.NetParameter()\n",
    "    net.CopyFrom(orig_net)\n",
    "    layers = list(net.layer)\n",
    "    new_layers = []\n",
    "    for layer in layers:\n",
    "        if layer.type == \"Convolution\" and layer.name.endswith(\"_D\"):\n",
    "\n",
    "            kernel_size = layer.convolution_param.kernel_size\n",
    "            num_outputs = layer.convolution_param.num_output\n",
    "\n",
    "            # Replace decoding convolution with a 1D horizntal filter\n",
    "            hlayer = caffe.proto.caffe_pb2.LayerParameter()\n",
    "            hlayer.CopyFrom(layer)\n",
    "            hlayer.convolution_param.ClearField('kernel_size')\n",
    "            hlayer.convolution_param.ClearField('pad')\n",
    "            hlayer.convolution_param.kernel_w = kernel_size**2\n",
    "            hlayer.convolution_param.pad_w = (kernel_size**2-1)/2\n",
    "            hlayer.convolution_param.kernel_h = 1\n",
    "            hlayer.convolution_param.pad_h = 0\n",
    "            hlayer.name = layer.name + \"_H\"\n",
    "            hlayer.top[0] = hlayer.name\n",
    "            \n",
    "            # add batch normalization\n",
    "            hbn =  caffe.proto.caffe_pb2.LayerParameter()\n",
    "            hbn.name = hlayer.name + \"_bn\"\n",
    "            hbn.type=\"BN\"\n",
    "            hbn.bottom.append(hlayer.top[0])\n",
    "            hbn.top.append(hlayer.top[0])\n",
    "            hbn.param.add(lr_mult=1.0, decay_mult=1.0)\n",
    "            hbn.param.add(lr_mult=1.0, decay_mult=0.0)\n",
    "            hbn.bn_param.scale_filler.type='constant'\n",
    "            hbn.bn_param.scale_filler.value=1.0\n",
    "            hbn.bn_param.shift_filler.type='constant'\n",
    "            hbn.bn_param.shift_filler.value=1.0\n",
    "\n",
    "            # add a 1D vertical filter\n",
    "            vlayer = caffe.proto.caffe_pb2.LayerParameter()\n",
    "            vlayer.CopyFrom(layer)\n",
    "            vlayer.convolution_param.ClearField('kernel_size')\n",
    "            vlayer.convolution_param.ClearField('pad')\n",
    "            vlayer.convolution_param.kernel_w = 1\n",
    "            vlayer.convolution_param.pad_w = 0\n",
    "            vlayer.convolution_param.kernel_h = kernel_size**2\n",
    "            vlayer.convolution_param.pad_h = (kernel_size**2-1)/2\n",
    "            vlayer.name = layer.name + \"_V\"\n",
    "\n",
    "            vlayer.bottom[0] = hlayer.top[0]\n",
    "\n",
    "            new_layers.append(hlayer)\n",
    "            new_layers.append(hbn)\n",
    "            new_layers.append(vlayer)\n",
    "        else:\n",
    "            new_layers.append(layer)\n",
    "    \n",
    "    while len(net.layer):\n",
    "        net.layer.pop()\n",
    "    net.layer.extend(new_layers)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the net to use for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before executing these cells, copy the net used to train the 'i12' classifier into this folder and name it 'training-net.prototxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_net = read_net_proto('training-net.prototxt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "modified_train_net = modify_layers_for_anisotropy(train_net)\n",
    "# summarize_net(modified_train_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_net_proto(path, net):\n",
    "    new_proto = google.protobuf.text_format.MessageToString(net)\n",
    "    with open(path, 'w') as f:\n",
    "        f.write(new_proto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_net_proto('modified-training-net.prototxt', modified_train_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the net to use for inference / testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before executing these cells, copy the net used to do inference with the 'i12' classifier into this folder and name it 'original-inferenc-net.prototxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "infer_net_path = 'original-inference-net.prototxt'\n",
    "infer_net = read_net_proto(infer_net_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_infer_net = caffe.proto.caffe_pb2.NetParameter()\n",
    "new_infer_net =  modify_layers_for_anisotropy(infer_net)\n",
    "\n",
    "# Make sure any newly added BN layers are set to do INFERENCE  (in-place)\n",
    "for layer in new_infer_net.layer._values:\n",
    "    if layer.type == 'BN':\n",
    "        layer.bn_param.bn_mode=layer.bn_param.INFERENCE\n",
    "\n",
    "# The i12 net did not do softmax or classification (argmax as part of the net.\n",
    "# Here we add the softmax and argmax layers \n",
    "# modifies new_infer_net in-place\n",
    "for layer in infer_net.layer._values[91:]:\n",
    "    softmax = caffe.proto.caffe_pb2.LayerParameter()\n",
    "    softmax.softmax_param.engine = softmax.softmax_param.CUDNN\n",
    "    softmax.type = u'Softmax'\n",
    "    softmax.name = layer.name.replace('conv-', 'prob-')\n",
    "    softmax.top.append(softmax.name)\n",
    "    softmax.bottom.append(layer.top[0])\n",
    "\n",
    "    label = caffe.proto.caffe_pb2.LayerParameter()\n",
    "    label.name=layer.name.replace('conv-', 'label-')\n",
    "    label.top.append(label.name)\n",
    "    label.bottom.append(softmax.top[0])\n",
    "    label.type=u'ArgMax'\n",
    "    label.argmax_param.axis = 1\n",
    "    \n",
    "    new_infer_net.layer.add().CopyFrom(softmax)\n",
    "    new_infer_net.layer.add().CopyFrom(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_net_proto('modified-inference-net.prototxt', new_infer_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save a non-bayesian version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print ','.join(set([layer.type for layer in new_infer_net.layer]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dropouts = [layer for layer in new_infer_net.layer if layer.type == 'Dropout']\n",
    "print \"Found\", len(dropouts), \"dropout layers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for dropout in dropouts:\n",
    "    if dropout.dropout_param.HasField('sample_weights_test'):\n",
    "        print \"Dropout\", dropout.name, \"_was_ set to work during testing...\",\n",
    "        dropout.dropout_param.ClearField('sample_weights_test')\n",
    "        print \"not anymore though!\"\n",
    "    else:\n",
    "        print \"Dropout\", dropout.name, \"is NOT set to work during testing...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_net_proto('non-bayesian-inference-net.prototxt', new_infer_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Test \n",
    "** Make Sure Things Load Right**\n",
    "- The net should load without crashing everything\n",
    "- The tops should ONLY be the 'label-' layers, or the 'loss' layers, if everything is connected properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import caffe\n",
    "caffe.set_device(0)\n",
    "caffe.set_mode_gpu()\n",
    "\n",
    "import facade_layers\n",
    "reload(facade_layers)\n",
    "net = caffe.Net(new_proto_path, 'deploy/test_weights.caffemodel', caffe.TRAIN)\n",
    "\n",
    "results = net.forward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I have properly connected things, these should be just the 'loss' layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set the solver parameters to use the new net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "solver = caffe.proto.caffe_pb2.SolverParameter()\n",
    "Parse(open('solver.prototxt').read(), solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "solver.net = os.path.abspath('modified-training-net.prototxt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('solver.prototxt', 'w') as f:\n",
    "    f.write(google.protobuf.text_format.MessageToString(solver))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we can start training **almost**. This cost me 1000 iterations, I forgot to make the folder that will hold the snapshots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.path.isdir(os.path.dirname(solver.snapshot_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs(os.path.dirname(solver.snapshot_prefix))\n",
    "    print \"Since caffe won't do it for us (ugh!) I made the folder needed to hold our snapshots\"\n",
    "except OSError as e:\n",
    "    print \"Ok, it's alright, we must have already made that directory.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I should be able to 'start-training.sh'"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
